{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khlebovich-Alexandra/horoscope_generator/blob/master/text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovpZyIhNIgoq"
      },
      "source": [
        "# Text generation with an RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yG_n40gFzf9s",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1KtZ8OTz5Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "posts = pd.read_csv('https://raw.githubusercontent.com/Khlebovich-Alexandra/horoscope_generator/master/Data/final_posts.csv', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mV45ELxx_X5",
        "colab_type": "code",
        "outputId": "b66355b4-8b73-48d1-8a3d-e686bd522855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        }
      },
      "source": [
        "posts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "      <th>date</th>\n",
              "      <th>type</th>\n",
              "      <th>index in posts</th>\n",
              "      <th>domain</th>\n",
              "      <th>index_before_concat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>сегодня вы можете почувствовать незащищенность...</td>\n",
              "      <td>339</td>\n",
              "      <td>11 декабря</td>\n",
              "      <td>business</td>\n",
              "      <td>0</td>\n",
              "      <td>ribyhoroscop</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>вам звёзды рекомендуют сегодня больше работать...</td>\n",
              "      <td>303</td>\n",
              "      <td>11 декабря</td>\n",
              "      <td>love</td>\n",
              "      <td>0</td>\n",
              "      <td>ribyhoroscop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>если сегодня вы почувствуете робость, или, тог...</td>\n",
              "      <td>215</td>\n",
              "      <td>11 декабря</td>\n",
              "      <td>simple</td>\n",
              "      <td>0</td>\n",
              "      <td>ribyhoroscop</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>сегодня звезды рекомендуют вам заняться коррек...</td>\n",
              "      <td>278</td>\n",
              "      <td>10 декабря</td>\n",
              "      <td>business</td>\n",
              "      <td>1</td>\n",
              "      <td>ribyhoroscop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>сегодня ваш любимый человек признается в том, ...</td>\n",
              "      <td>273</td>\n",
              "      <td>10 декабря</td>\n",
              "      <td>love</td>\n",
              "      <td>1</td>\n",
              "      <td>ribyhoroscop</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26957</th>\n",
              "      <td>день преобразования космических энергий, получ...</td>\n",
              "      <td>544</td>\n",
              "      <td>2 марта</td>\n",
              "      <td>simple</td>\n",
              "      <td>2648</td>\n",
              "      <td>strelechoroscop</td>\n",
              "      <td>4575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26958</th>\n",
              "      <td>завтра - полон перемен для вас. поэтому строит...</td>\n",
              "      <td>256</td>\n",
              "      <td>1 марта</td>\n",
              "      <td>simple</td>\n",
              "      <td>2649</td>\n",
              "      <td>strelechoroscop</td>\n",
              "      <td>4576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26959</th>\n",
              "      <td>утром не мешкая приступайте к работе или завяз...</td>\n",
              "      <td>441</td>\n",
              "      <td>28 февраля</td>\n",
              "      <td>simple</td>\n",
              "      <td>2650</td>\n",
              "      <td>strelechoroscop</td>\n",
              "      <td>4577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26960</th>\n",
              "      <td>общительность и дружелюбие вас сегодня могут н...</td>\n",
              "      <td>453</td>\n",
              "      <td>27 февраля</td>\n",
              "      <td>simple</td>\n",
              "      <td>2651</td>\n",
              "      <td>strelechoroscop</td>\n",
              "      <td>4578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26961</th>\n",
              "      <td>свободное общение может стать затруднительным....</td>\n",
              "      <td>505</td>\n",
              "      <td>26 февраля</td>\n",
              "      <td>simple</td>\n",
              "      <td>2652</td>\n",
              "      <td>strelechoroscop</td>\n",
              "      <td>4579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26962 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ...  index_before_concat\n",
              "0      сегодня вы можете почувствовать незащищенность...  ...                    0\n",
              "1      вам звёзды рекомендуют сегодня больше работать...  ...                    1\n",
              "2      если сегодня вы почувствуете робость, или, тог...  ...                    2\n",
              "3      сегодня звезды рекомендуют вам заняться коррек...  ...                    3\n",
              "4      сегодня ваш любимый человек признается в том, ...  ...                    4\n",
              "...                                                  ...  ...                  ...\n",
              "26957  день преобразования космических энергий, получ...  ...                 4575\n",
              "26958  завтра - полон перемен для вас. поэтому строит...  ...                 4576\n",
              "26959  утром не мешкая приступайте к работе или завяз...  ...                 4577\n",
              "26960  общительность и дружелюбие вас сегодня могут н...  ...                 4578\n",
              "26961  свободное общение может стать затруднительным....  ...                 4579\n",
              "\n",
              "[26962 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FFkwZek_59l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "posts.drop(['date', 'type', 'index in posts', 'domain', 'index_before_concat'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82TFR9vpzuo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "posts.drop(np.argmax(posts.length), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a7aWB6Y6psw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_spaces(x):\n",
        "    literals = ',.?!;:()'\n",
        "    for literal in literals:\n",
        "        if literal in x:\n",
        "            x = x.replace(literal, ' ' + literal + ' ')\n",
        "            \n",
        "    pattern_bad_spaces_1 = re.compile(r'(^ +)|( +$)')\n",
        "    pattern_bad_spaces_2 = re.compile(r'(  +)|(\\t)')\n",
        "    x = re.sub(pattern_bad_spaces_1, '', x)\n",
        "    x = re.sub(pattern_bad_spaces_2, ' ', x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSO91hZP2IqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(x):\n",
        "    res = re.split(re.compile(r'[ ]+'), x.lower())\n",
        "    while '' in res:\n",
        "        res.remove('')\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPVgqjg4kAEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vocab(texts):\n",
        "    texts = pd.Series(texts)\n",
        "    texts = texts.map(add_spaces)\n",
        "    texts = texts.map(split)\n",
        "    word_index = {}\n",
        "    word_index[\"<Заполнитель>\"] = 0\n",
        "    word_index[\"<Начало последовательности>\"] = 1\n",
        "    word_index[\"<Не используется>\"] = 2\n",
        "    word_index[\"<Неизвестное слово>\"] = 3\n",
        "    ind = 4\n",
        "    for text in texts:\n",
        "        for word in text:\n",
        "            if not (word in word_index):\n",
        "                word_index[word] = ind\n",
        "                ind += 1\n",
        "    return word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcWQdfGC9faV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_to_int(word):\n",
        "    if word in word_index:\n",
        "        return word_index[word]\n",
        "    return 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgw9b2NvOZsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_by_index(index):\n",
        "    for word, value in word_index.items():\n",
        "        if index == value:\n",
        "            return word\n",
        "    return ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M98ZykAWi58p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(text):\n",
        "    text = add_spaces(text)\n",
        "    text = split(text)\n",
        "    text = list(map(word_to_int, text))\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20IzUjIekiq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = create_vocab(posts.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiWbROst5VT0",
        "colab_type": "code",
        "outputId": "99d13814-1f1a-46f1-f4bf-7dc8ae7bbf0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_index['.']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaHhwmDX5VdJ",
        "colab_type": "code",
        "outputId": "bea483d0-02ce-4b84-e2ad-a6cf5de67a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(word_index)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47923"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD_ovvDAlZdC",
        "colab_type": "code",
        "outputId": "b3c53eee-d3c6-417f-bf34-6a5697130260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(create_dataset(posts.text[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 9, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 14, 28, 29, 30, 31, 32, 33, 19, 34, 35, 36, 37, 19, 38, 39, 40, 41, 42, 43, 44, 14, 45, 46, 47, 25, 48, 49, 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_um9i5Z5Vlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "posts.text = posts.text.map(create_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODFF1IxCYLnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "posts.length = posts.text.map(len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnx8JPUW_iBH",
        "colab_type": "text"
      },
      "source": [
        "Save DataFrame and vocabluary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu2ypVPl_frW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "posts.to_csv('posts_word_to_int.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFtZFyOh_fv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "with open('vocab.json', 'w') as fp:\n",
        "    json.dump(word_index, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1aY0m00BuLP",
        "colab_type": "text"
      },
      "source": [
        "Padding seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXpZnNsJbo07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_list_of_ints(x):\n",
        "    if isinstance(x, str):\n",
        "        x = x.strip('][').split(', ')\n",
        "    return list(map(int, x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbv3YeyiW_29",
        "colab_type": "code",
        "outputId": "f547a395-f182-465c-b765-5ac8f1a78f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "posts = pd.read_csv('posts_word_to_int.csv', index_col=0)\n",
        "posts.text = posts.text.map(get_list_of_ints)\n",
        "posts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[50, 51, 52, 4, 53, 54, 14, 55, 56, 57, 58, 59...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[89, 4, 5, 90, 91, 19, 56, 19, 92, 93, 94, 19,...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[4, 109, 52, 50, 110, 111, 56, 112, 113, 114, ...</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[4, 136, 137, 138, 139, 11, 140, 19, 20, 141, ...</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26957</th>\n",
              "      <td>[199, 7429, 7906, 19954, 19, 8101, 20213, 8982...</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26958</th>\n",
              "      <td>[3016, 81, 2294, 3598, 47, 25, 14, 302, 6957, ...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26959</th>\n",
              "      <td>[8803, 121, 47918, 13480, 71, 535, 56, 35595, ...</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26960</th>\n",
              "      <td>[8673, 9, 5898, 25, 4, 702, 23496, 87, 19815, ...</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26961</th>\n",
              "      <td>[4187, 2385, 254, 595, 7041, 14, 5, 6, 160, 36...</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26961 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  length\n",
              "0      [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...      53\n",
              "1      [50, 51, 52, 4, 53, 54, 14, 55, 56, 57, 58, 59...      49\n",
              "2      [89, 4, 5, 90, 91, 19, 56, 19, 92, 93, 94, 19,...      40\n",
              "3      [4, 109, 52, 50, 110, 111, 56, 112, 113, 114, ...      46\n",
              "4      [4, 136, 137, 138, 139, 11, 140, 19, 20, 141, ...      46\n",
              "...                                                  ...     ...\n",
              "26957  [199, 7429, 7906, 19954, 19, 8101, 20213, 8982...      81\n",
              "26958  [3016, 81, 2294, 3598, 47, 25, 14, 302, 6957, ...      40\n",
              "26959  [8803, 121, 47918, 13480, 71, 535, 56, 35595, ...      63\n",
              "26960  [8673, 9, 5898, 25, 4, 702, 23496, 87, 19815, ...      68\n",
              "26961  [4187, 2385, 254, 595, 7041, 14, 5, 6, 160, 36...      88\n",
              "\n",
              "[26961 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQTvyMT9zoc6",
        "colab_type": "code",
        "outputId": "240a7b22-19ca-4be1-d679-b1b252bb1bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "posts.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>26961.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>50.237640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.919764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>48.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>58.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>129.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             length\n",
              "count  26961.000000\n",
              "mean      50.237640\n",
              "std       15.919764\n",
              "min        4.000000\n",
              "25%       40.000000\n",
              "50%       48.000000\n",
              "75%       58.000000\n",
              "max      129.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67kAP_hvz5Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AargE3YdaTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = pad_sequences(posts.text, maxlen, padding='post')\n",
        "texts = tf.data.Dataset.from_tensor_slices(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gKOQB0YMg_u0",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = texts.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SayoM0ZdhDYu",
        "colab_type": "code",
        "outputId": "37dab40f-77aa-4afb-ce84-34d25abc99ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.take(1)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((49,), (49,)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoofKWQPhZkE",
        "colab_type": "code",
        "outputId": "558e3981-ba01-410a-93b5-651c7b998d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(dataset[:5], dataset[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, get_word_by_index(input_idx)))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, \n",
        "                                                get_word_by_index(target_idx)))"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-282-f7455c1e3552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step {:4d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  input: {} ({:s})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_word_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     print(\"  expected output: {} ({:s})\".format(target_idx, \n\u001b[1;32m      5\u001b[0m                                                 get_word_by_index(target_idx)))\n",
            "\u001b[0;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXU2AHXkiaoX",
        "colab_type": "code",
        "outputId": "66f93447-2ddc-4ae3-f5a2-cbcb508d2d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 49), (64, 49)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxYcQI5uCs7u",
        "colab_type": "code",
        "outputId": "7b9b3708-7663-4a2a-d9c4-2f3f638ae465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# define model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[BATCH_SIZE, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (64, None, 256)           12268288  \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (64, None, 47923)         49121075  \n",
            "=================================================================\n",
            "Total params: 65,327,667\n",
            "Trainable params: 65,327,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "865ce535-5cf0-48b2-d89e-93372600d7d2",
        "id": "RzjfulxIp3hZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 49, 47923) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4V4MfFg0RQJg",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YqFMUQc_UFgM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a6f36141-e5b9-46c1-9b71-2dd80fb2bab5"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9981,  6889, 36817, 19912, 31095, 37149, 27442, 33349, 16949,\n",
              "       13260, 17136, 19531, 22942, 11543, 46208, 21612, 30696, 24334,\n",
              "       13966,  9663, 14451, 39965,  9993, 10153, 36351, 41017,  7143,\n",
              "       37678, 21416, 29545, 11653, 10981,  6204, 11310, 17756, 33332,\n",
              "       40570,  8428, 45829, 19308, 33244, 20903, 46799, 41686, 17884,\n",
              "        4065, 33484, 14124, 19611])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "Decode these to see the text predicted by this untrained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xWcFwPwLSo05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a33135d7-5874-424e-e6e4-90f34b3a5137"
      },
      "source": [
        "print(\"Input: \\n\", repr(\" \".join([get_word_by_index(i) for i in input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\" \".join([get_word_by_index(i) for i in sampled_indices])))"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'это хорошее время для зарождения новых деловых проектов , переговоров и бесед , из которых можно почерпнуть много новых идей . для любви это волшебное , но несколько странное время . отношениям может не хватать тепла и нежности , но возможно быстрое сближение на уровне общих интересов и увлечений'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'волнуетесь случая приживется приукрашенном руководят мотивирует затруднительна срывов косвенное грандиозные десятка отклонять несбывшимися неотложных необычна безотказное уютнее необъятное моральным ревнивец спешка неуютного драгоценное средстве доверяют подхватывать банковский современная разойтись несправедливостью шоппинг встречался удовольствий утренние сосредоточенными «завернуть» пищевой беспрестанно рассеивайтесь кране знаеть недоумевающим обзаведитесь дешёвый взбодрит причиной требовательностью осмотрительней упростить'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UAjbjY03eiQ4"
      },
      "source": [
        "The standard `tf.keras.losses.sparse_categorical_crossentropy` loss function works in this case because it is applied across the last dimension of the predictions.\n",
        "\n",
        "Because our model returns logits, we need to set the `from_logits` flag.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4HrXTACTdzY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61948842-8828-45f3-d2e0-022f4249ebf4"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 49, 47923)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       10.777245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jeOXriLcymww"
      },
      "source": [
        "Configure the training procedure using the `tf.keras.Model.compile` method. We'll use `tf.keras.optimizers.Adam` with default arguments and the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DDl1_Een6rL0",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ieSJdchZggUj"
      },
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C6XBUUavgF56"
      },
      "source": [
        "Use a `tf.keras.callbacks.ModelCheckpoint` to ensure that checkpoints are saved during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W6fWTriUZP-n",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IxdOA-rgyGvs"
      },
      "source": [
        "To keep training time reasonable, use 10 epochs to train the model. In Colab, set the runtime to GPU for faster training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7yGBE2zxMMHs",
        "colab": {}
      },
      "source": [
        "EPOCHS=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a0286050-f474-46f3-f446-9b87c3cea630"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 421 steps\n",
            "421/421 [==============================] - 91s 215ms/step - loss: 6.5237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JIPcXllKjkdr"
      },
      "source": [
        "### Restore the latest checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LyeYRiuVjodY"
      },
      "source": [
        "To keep this prediction step simple, use a batch size of 1.\n",
        "\n",
        "Because of the way the RNN state is passed from timestep to timestep, the model only accepts a fixed batch size once built.\n",
        "\n",
        "To run the model with a different `batch_size`, we need to rebuild the model and restore the weights from the checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zk2WJ2-XjkGz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc616073-bc0a-40e1-aa4a-a544a71cf590"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ25OdE8Z0HZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bc55746-459a-4fa9-ebc5-4c69586a2247"
      },
      "source": [
        "tf.train.load_checkpoint('./training_checkpoints/ckpt_40')"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python._pywrap_checkpoint_reader.CheckpointReader at 0x7faa700d8570>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LycQ-ot_jjyu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7f8256b-208d-4fff-fdc8-8ff50caea930"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[1, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "\n",
        "model.load_weights('./training_checkpoints/ckpt_40')\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "71xa6jnYVrAN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "05448fcb-338a-46d4-f5b3-7fe82ed9190e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (1, None, 256)            12268288  \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (1, None, 47923)          49121075  \n",
            "=================================================================\n",
            "Total params: 65,327,667\n",
            "Trainable params: 65,327,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "### The prediction loop\n",
        "\n",
        "The following code block generates the text:\n",
        "\n",
        "* It Starts by choosing a start string, initializing the RNN state and setting the number of characters to generate.\n",
        "\n",
        "* Get the prediction distribution of the next character using the start string and the RNN state.\n",
        "\n",
        "* Then, use a categorical distribution to calculate the index of the predicted character. Use this predicted character as our next input to the model.\n",
        "\n",
        "* The RNN state returned by the model is fed back into the model so that it now has more context, instead than only one word. After predicting the next word, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted words.\n",
        "\n",
        "\n",
        "![To generate text the model's output is fed back to the input](https://github.com/Khlebovich-Alexandra/horoscope_generator/blob/master/images/text_generation_sampling.png?raw=1)\n",
        "\n",
        "Looking at the generated text, you'll see the model knows when to capitalize, make paragraphs and imitates a Shakespeare-like writing vocabulary. With the small number of training epochs, it has not yet learned to form coherent sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WvuwZBX5Ogfd",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string, num_of_words, temp):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  text = start_string\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_of_words):\n",
        "      input_eval = create_dataset(start_string)\n",
        "      input_eval = pad_sequences([input_eval], maxlen - 1, padding='post')\n",
        "\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the word returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      new_word = get_word_by_index(predicted_id)\n",
        "      text = text + ' ' + new_word\n",
        "\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvUY75TeXDxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3f7ef11-9cd9-42e2-9119-d2a29176d885"
      },
      "source": [
        "generate_text(model, 'сегодня вам ', 10, 4.5)"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'сегодня вам  стартовые энергетической более <Заполнитель> жребий обстоятельству следствие роднёй поворотами крайностей'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVNddTOde3Pu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbad56be-1c8a-4639-91f3-080f70e91bf9"
      },
      "source": [
        "generate_text(model, 'сегодня вам ', 10, 55)"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'сегодня вам  фотоаппарат новому запускайте поднятие утерянную содействовать заслуживает прослужат сходив зачем-то'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fRyJvyBe3b8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0111d76-f640-4b59-d31e-55c6fff46558"
      },
      "source": [
        "generate_text(model, 'сегодня вам ', 10, 28)"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'сегодня вам  лестнице изрядной препятствий запоминающиеся пожелание моут участвующим основанной спонсорство раскритиковать'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AM2Uma_-yVIq"
      },
      "source": [
        "The easiest thing you can do to improve the results it to train it for longer (try `EPOCHS=30`).\n",
        "\n",
        "You can also experiment with a different start string, or try adding another RNN layer to improve the model's accuracy, or adjusting the temperature parameter to generate more or less random predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y4QwTjAM6A2O"
      },
      "source": [
        "## Advanced: Customized Training\n",
        "\n",
        "The above training procedure is simple, but does not give you much control.\n",
        "\n",
        "So now that you've seen how to run the model manually let's unpack the training loop, and implement it ourselves. This gives a starting point if, for example, to implement _curriculum learning_ to help stabilize the model's open-loop output.\n",
        "\n",
        "We will use `tf.GradientTape` to track the gradients. You can learn more about this approach by reading the [eager execution guide](https://www.tensorflow.org/guide/eager).\n",
        "\n",
        "The procedure works as follows:\n",
        "\n",
        "* First, initialize the RNN state. We do this by calling the `tf.keras.Model.reset_states` method.\n",
        "\n",
        "* Next, iterate over the dataset (batch by batch) and calculate the *predictions* associated with each.\n",
        "\n",
        "* Open a `tf.GradientTape`, and calculate the predictions and loss in that context.\n",
        "\n",
        "* Calculate the gradients of the loss with respect to the model variables using the `tf.GradientTape.grads` method.\n",
        "\n",
        "* Finally, take a step downwards by using the optimizer's `tf.train.Optimizer.apply_gradients` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_XAm7eCoKULT",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qUKhnZtMVpoJ",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b4kH1o0leVIp",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, target):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inp)\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            target, predictions, from_logits=True))\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d4tSNwymzf-q",
        "colab": {}
      },
      "source": [
        "# Training step\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  # initializing the hidden state at the start of every epoch\n",
        "  # initally hidden is None\n",
        "  hidden = model.reset_states()\n",
        "\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    loss = train_step(inp, target)\n",
        "\n",
        "    if batch_n % 100 == 0:\n",
        "      template = 'Epoch {} Batch {} Loss {}'\n",
        "      print(template.format(epoch+1, batch_n, loss))\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
        "  print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlzjJVB42AzH",
        "colab_type": "code",
        "outputId": "f7b991b2-e001-48df-fdde-63e9d42e6076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  training_checkpoints\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BshduFK_5xMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "json_file = open('posts_model.json', 'w')\n",
        "json_file.write(model_json)\n",
        "json_file.close()\n",
        "model.save_weights('posts_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK0wOar7eVeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ZV2H0X6lye",
        "colab_type": "code",
        "outputId": "f49fe1c7-c355-4d37-d61a-52d11d0b16c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "posts_word_to_int.csv  sample_data  vocab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR0iEZPy6mcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFFo3yb56r6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('posts_word_to_int.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCaXhVwz60Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('vocab.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Qi8Vqt7BNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}